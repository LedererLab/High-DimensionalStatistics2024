---
title: "Project_LASSO-Implementation"
output: 
  html_notebook:
    number_sections: true
---
# Implementing the Coordinate Decent
## Soft-Thresholding
```{r}
SoftThresholding<-function(z,lambda){
  if (z>lambda){
    return(z-lambda)
  }
  if (z<(-lambda)){
    return(z+lambda)
  } 
  return(0)
}
```


```{r}
#Test
#x=-10:10
#y=rep(0,length(x))
#for(i in 1:length(x)){
#  y[i]=SoftThresholding(x[i],3)
#}
#plot(x,y)
```

## Coordinate Decent
```{r}
LassoCoordinateDecent<-function(design, outcome, tuningparameter, nbrcycles, startingpoint=NULL){
  #generating a random starting point for the estimator if no starting point is given
  if (is.null(startingpoint)){
    estimator<-matrix(rnorm(dim(design)[2],0,1),nrow=dim(design)[2],ncol=1)
  }
  else {
    estimator<-matrix(startingpoint,nrow=dim(design)[2],ncol=1)
  }
  #Computing fixed arguments:
  a=rep(NULL,dim(design)[2])
  b=rep(NULL,dim(design)[2])
  C=matrix(rep(0,dim(design)[2]*(dim(design)[2]-1)),nrow=dim(design)[2],ncol=(dim(design)[2]-1))
  d=rep(NULL,dim(design)[2])
  for (i in 1:dim(design)[2]){
    a[i]=t(design[,i])%*%design[,i]   #squared l2-norms of the predictors (columns of the design)
    b[i]=t(design[,i])%*%outcome      
    C[i,]=t(design[,i])%*%design[,-i]
    d[i]=tuningparameter/a[i]
  }
  #sampling the indexes to gor randomly through the vector
  index=sample(1:dim(design)[2]) 
  #actual coordinate decent
  for (k in 1:nbrcycles){    
    for (i in 1:dim(design)[2]){
      estimator[index[i]]=SoftThresholding((b[index[i]]-C[index[i],]%*%estimator[-index[i]])/a[index[i]],
                                           d[index[i]])
    }
  }
  return(estimator)
}
```

# Testing coordinate decent with data from Lab 4
```{r}
set.seed(1)
n <- 100; p <- 500
design <- matrix(rnorm(n*p,mean=0,sd=1),nrow=100,ncol=500)
regression.vector <- c(1,1,1,rep(0,p-3))
outcome <- design%*%regression.vector+rnorm(n,mean=0,sd=0.01) 

LassoCoordinateDecent(design, outcome, tuningparameter = 0.225, nbrcycles=200,
                      startingpoint=rep(0,dim(design)[2]))
```
# Testing the Lasso-Implementation on Real Data

Socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR to predict the total number of violent crimes per 100.000 residents.

## Importing a Real Data Set
```{r}
#importing the data
data.original=read.csv("/Users/milena/HDStatistics_Project/High-DimensionalStatistics2024/MilenaBraig/communities_data.csv", header=FALSE, sep=",")
#deleting non-predictive features
data=data.original[,6:128]  
#saving the dimensions of the data
n=dim(data)[1]   
p=dim(data)[2]
#converting to numeric values
data=as.numeric(as.matrix(data, nrow=n,ncol=p))   
#converting the vector from as.numeric back to a matrix
data=matrix(data,nrow=n,ncol=p)
#omitting samples wit NA values
data=na.omit(data)
#saving the reduced number of samples
n=dim(data)[1]

#importing the feature names
data.features<-read.csv("/Users/milena/HDStatistics_Project/High-DimensionalStatistics2024/MilenaBraig/communities_names_edited.csv", header=FALSE, sep=";")
#adding the feature descriptions as column names
names(data.original)<-data.features[,2]
#omiting the non-predictive features
data.features.pred=data.frame(data.features[6:127,])

print(data.features[,2])
```


## Divinding the Data into Data for Cross Validation, Training, and Testing
```{r}
size.training=100
size.testing=100
size.cv=100
#training data
indexes.training <- sample(c(1:dim(data)[1]), size.training)
data.train=data[indexes.training,]
#testing data
data.rest=data[-indexes.training,]
indexes.testing=sample(c(1:dim(data.rest)[1]), size.testing)
data.test=data.rest[indexes.testing,]
#data for cross-validation
data.rest=data.rest[-indexes.testing,]
indexes.cv=sample(c(1:dim(data.rest)[1]), size.cv)
data.cv=data.rest[indexes.cv,]
```

## Centering and Scaling
```{r}
#centering training data
mean=colMeans(data.train)
for (i in 1:dim(data.train)[2]){
  data.train.centered[,i]=data.train[,i]-mean[i] 
}
#scaling training data
sd=apply(data.train.centered,MARGIN=2,FUN=sd)
for (i in 1:dim(data.train)[2]){
  data.train.scaled[,i]=data.train.centered[,i]*1/sd[i]
}
#centering and scaling test and cross-validation data
for (i in 1:dim(data.train)[2]){
  data.test.scaled[,i]=(data.test[,i]-mean[i])/sd[i]
  data.cv.scaled[,i]=(data.cv[,i]-mean[i])/sd[i]
}
#dividing training data
design.train=data.train.scaled[,-dim(data)[2]]
outcome.train=data.train.scaled[,dim(data)[2]]
#dividing testing data
design.test=data.test.scaled[,-dim(data)[2]]
outcome.test=data.test.scaled[,dim(data)[2]]
#dividing data for cross validation
design.cv=data.cv.scaled[,-dim(data)[2]]
outcome.cv=data.cv.scaled[,dim(data)[2]]
```


## K-Fold Cross-Validation
```{r}
l2norm<-function(x){
  return(sqrt(sum(x^2)))
}

set.seed(10)
KCrossValidation <- function(design, outcome, tuning.parameters, nbrfolds){
  #splitting the data into k folds
  size.fold=floor(dim(design)[1]/nbrfolds)
  Folds=matrix(rep(0,nbrfolds*size.fold), nrow=nbrfolds, ncol=size.fold)
  indexes=sample(1:dim(design)[1],dim(design)[1])  
  for(i in 1:nbrfolds){
    Folds[i,]=indexes[((i-1)*size.fold)+1:size.fold]
  }
  #cross-validating 
  min.avg.error=Inf
  best.tuningparameter=NULL
  for(j in 1:length(tuning.parameters)){ #for each tuning parameter
    error=rep(NULL,nbrfolds)
    for(k in 1:nbrfolds){ #for each data separation
      #training the model 
      estimator=LassoCoordinateDecent(design[-Folds[k,],], outcome[-Folds[k,]], tuning.parameters[j],
                                    nbrcycles=200, startingpoint = rep(0,dim(design)[2]) )
      #testing the model
      error[k]=l2norm(outcome[Folds[k,]]-design[Folds[k,],]%*%estimator)
    }
    #average error
    avg.error=(sum(error)/nbrfolds)
    #storing the minimal error and the according tuning parameter
    if (avg.error<min.avg.error){
      min.avg.error=avg.error
      best.tuningparameter=tuning.parameters[j]
    }
  }
  return(best.tuningparameter)
}
nbrfolds=10
#KCrossValidation(design.cv[1:10,],outcome.cv[1:10],runif(nbrfolds, min=0, max=3), nbrfolds)
tuningparameter=KCrossValidation(design.cv,outcome.cv,runif(100, min=0, max=100), nbrfolds)
tuningparameter   
```

## Training the Model with the Selected Tuning Parameter
```{r}
estimator=LassoCoordinateDecent(design.train, outcome.train, tuningparameter, nbrcycles=200,
                                startingpoint=rep(0,dim(design.train)[2]))
estimator
```

## Testing the Model
```{r}
error=l2norm(outcome.test-design.test%*%estimator)
error
```

## Evaluation:

```{r}
#support of the estimator
support=NULL
for(i in 1:length(estimator)){
  if(estimator[i]!=0){
    support[length(support)+1]=i
  }
}
```


```{r}
cat("The cross validation gives a tuning parameter of ", tuningparameter, ". Training the model with this tuning parameter results in an l2-error testing error of ", error, ". Looking at the estimator, we see that there are only", length(support), "features that are regarded as relevant in our model. Those features are:\n")

print(data.features.pred[support,2])
```

```{r}
influence=data.frame(weight=estimator[support], Features=data.features.pred[support,2])
influence.ordered=influence[order(influence$weight,decreasing=TRUE),]
```
## Conclusion
```{r}
cat("- The model is comparativly sparse: ", length(support)," of", dim(design.train)[2]," features correspond to non-zero entries in the estimator. \n - There is no distinct focus on a type of in formation given by the features (heritage, income, employment, living situation, police) only the education is not regarded at all (apart from its possible influence on th employment).\n - The features with a negative influence on the number of violent crimes describe primarily model families, employment and income\n - The features with a positive influence on the number of violent crimes describe primarily conflicted living situations (divorce, homelesness, high rent compared to the income) and police presence")
```

